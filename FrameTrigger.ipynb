{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!git clone https://github.com/leonardozilli/FrameTrigger.git\n","%cd FrameTrigger/"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["!pip install transformers[torch] datasets -q"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-12 12:49:09.074289: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-02-12 12:49:09.122718: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-12 12:49:09.986854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["from src.fn17 import load_dataset_hf, load_dataset_nltk\n","from src.train import train, test\n","from src.predict import predict_triggers, predict_frames\n","from src.process_data import prepare_data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["CHECKPOINT = 'bert-base-cased'\n","TASK = 'frames'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package framenet_v17 to /home/leo/nltk_data...\n","[nltk_data]   Package framenet_v17 is already up-to-date!\n","100%|██████████| 107/107 [00:20<00:00,  5.14it/s]\n","100%|██████████| 107/107 [00:22<00:00,  4.81it/s]\n","100%|██████████| 107/107 [00:20<00:00,  5.14it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df1ec48940054490ac5d77f70ee8bf60","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3425 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"576014ea6a0f43a982d2c1e82cd9af2e","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/328 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de9920e618d04836be31e6b0ed08db2d","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1354 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 3425\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 328\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 1354\n","    })\n","})"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset = load_dataset_nltk()\n","tokenized_dataset = prepare_data(dataset, CHECKPOINT, task=TASK)\n","tokenized_dataset"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from nltk.corpus import framenet as fn\n","\n","id2label = {i: frame['name'] for i, frame in enumerate(fn.frames(), start=1)}\n","id2label[0] = \"None\"\n","label2id = {v: k for k, v in id2label.items()}"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["1222"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["len(id2label)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["2442"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["FRAME2ID = {}\n","\n","for i, frame in enumerate(fn.frames(), start=1):\n","    FRAME2ID[f'B-{frame[\"name\"]}'] = i * 2 - 1\n","    FRAME2ID[f'I-{frame[\"name\"]}'] = i * 2\n","\n","len(FRAME2ID)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["id2label = {}\n","\n","for i, frame in enumerate(fn.frames(), start=1):\n","    id2label[i*2-1] = f'B-{frame[\"name\"]}'\n","    id2label[i*2] = f'I-{frame[\"name\"]}'\n","\n","id2label[0] = \"None\"\n","\n","label2id = {v: k for k, v in id2label.items()}"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Jerusalem 's recorded history begins with its mention in Egyptian court records 4,000 years ago , but there had been human settlements here for centuries , probably millennia , before that .\n","['Jerusalem', \"'s\", 'recorded', 'history', 'begins', 'with', 'its', 'mention', 'in', 'Egyptian', 'court', 'records', '4,000', 'years', 'ago', ',', 'but', 'there', 'had', 'been', 'human', 'settlements', 'here', 'for', 'centuries', ',', 'probably', 'millennia', ',', 'before', 'that', '.']\n","['O', 'O', 'O', 'O', 'B-Process_start', 'O', 'O', 'B-Statement', 'O', 'O', 'B-Judicial_body', 'O', 'O', 'B-Measure_duration', 'B-Time_vector', 'O', 'O', 'B-Existence', 'O', 'I-Existence', 'B-People', 'B-Locale_by_use', 'O', 'O', 'B-Measure_duration', 'O', 'B-Likelihood', 'B-Calendric_unit', 'O', 'B-Time_vector', 'O', 'O']\n","[0, 0, 0, 0, 1747, 0, 0, 2155, 0, 0, 1275, 0, 0, 1423, 2275, 0, 0, 913, 0, 914, 1603, 1347, 0, 0, 1423, 0, 1325, 355, 0, 2275, 0, 0]\n","[101, 6167, 112, 188, 1802, 1607, 3471, 1114, 1157, 4734, 1107, 6210, 2175, 3002, 125, 117, 1288, 1201, 2403, 117, 1133, 1175, 1125, 1151, 1769, 7536, 1303, 1111, 3944, 117, 1930, 6159, 1424, 5813, 117, 1196, 1115, 119, 102]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[-100, 0, 0, 0, 0, 0, 1747, 0, 0, 2155, 0, 0, 1275, 0, 0, 0, 0, 1423, 2275, 0, 0, 913, 0, 914, 1603, 1347, 0, 0, 1423, 0, 1325, 355, 355, 355, 0, 2275, 0, 0, -100]\n"]}],"source":["for el in dataset['train'][30]:\n","    print(dataset['train'][0][el])\n","for el in tokenized_dataset['train'][30]:\n","    print(tokenized_dataset['train'][0][el])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label2id['Existence']"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["{'input_ids': [101,\n","  6167,\n","  112,\n","  188,\n","  1802,\n","  1607,\n","  3471,\n","  1114,\n","  1157,\n","  4734,\n","  1107,\n","  6210,\n","  2175,\n","  3002,\n","  125,\n","  117,\n","  1288,\n","  1201,\n","  2403,\n","  117,\n","  1133,\n","  1175,\n","  1125,\n","  1151,\n","  1769,\n","  7536,\n","  1303,\n","  1111,\n","  3944,\n","  117,\n","  1930,\n","  6159,\n","  1424,\n","  5813,\n","  117,\n","  1196,\n","  1115,\n","  119,\n","  102],\n"," 'token_type_ids': [0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0],\n"," 'attention_mask': [1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1],\n"," 'labels': [-100,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  874,\n","  0,\n","  0,\n","  1078,\n","  0,\n","  0,\n","  638,\n","  0,\n","  0,\n","  0,\n","  0,\n","  712,\n","  1138,\n","  0,\n","  0,\n","  457,\n","  0,\n","  457,\n","  802,\n","  674,\n","  0,\n","  0,\n","  712,\n","  0,\n","  663,\n","  178,\n","  178,\n","  178,\n","  0,\n","  1138,\n","  0,\n","  0,\n","  -100]}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset['train'][0]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"498801cbd7a5438a9904c528839089c5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3425 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bde04bdca4547198771abff7be435e8","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/328 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bc5869330d7400db5de19885a837f02","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1354 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 3425\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 328\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 1354\n","    })\n","})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["import importlib\n","import src.process_data\n","importlib.reload(src.process_data)\n","from src.process_data import prepare_data\n","tokenized_dataset = prepare_data(dataset, CHECKPOINT, task=TASK)\n","tokenized_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Jerusalem 's recorded history begins with its mention in Egyptian court records 4,000 years ago , but there had been human settlements here for centuries , probably millennia , before that .\n","['Jerusalem', \"'s\", 'recorded', 'history', 'begins', 'with', 'its', 'mention', 'in', 'Egyptian', 'court', 'records', '4,000', 'years', 'ago', ',', 'but', 'there', 'had', 'been', 'human', 'settlements', 'here', 'for', 'centuries', ',', 'probably', 'millennia', ',', 'before', 'that', '.']\n","['O', 'O', 'O', 'O', 'B-Process_start', 'O', 'O', 'B-Statement', 'O', 'O', 'B-Judicial_body', 'O', 'O', 'B-Measure_duration', 'B-Time_vector', 'O', 'O', 'B-Existence', 'O', 'I-Existence', 'B-People', 'B-Locale_by_use', 'O', 'O', 'B-Measure_duration', 'O', 'B-Likelihood', 'B-Calendric_unit', 'O', 'B-Time_vector', 'O', 'O']\n","[-1, -1, -1, -1, 874, -1, -1, 1078, -1, -1, 638, -1, -1, 712, 1138, -1, -1, 457, -1, 457, 802, 674, -1, -1, 712, -1, 663, 178, -1, 1138, -1, -1]\n"]}],"source":["for e in dataset['train'][0]:\n","    print(dataset['train'][0][e])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[101, 6167, 112, 188, 1802, 1607, 3471, 1114, 1157, 4734, 1107, 6210, 2175, 3002, 125, 117, 1288, 1201, 2403, 117, 1133, 1175, 1125, 1151, 1769, 7536, 1303, 1111, 3944, 117, 1930, 6159, 1424, 5813, 117, 1196, 1115, 119, 102]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[-100, -1, -1, -1, -1, -1, 874, -1, -1, 1078, -1, -1, 638, -1, -1, -1, -1, 712, 1138, -1, -1, 457, -1, 457, 802, 674, -1, -1, 712, -1, 663, 178, 178, 178, -1, 1138, -1, -1, -100]\n"]}],"source":["\n","for el in tokenized_dataset['train'][0]:\n","    print(tokenized_dataset['train'][0][el])"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["OUT_DIR = './models'\n","N_EPOCHS = 10\n","BATCH_SIZE = 64\n","LEARNING_RATE = 2e-5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train(pretrained_model=CHECKPOINT, task=TASK, dataset=tokenized_dataset,\n","    epochs=N_EPOCHS, batch_size=BATCH_SIZE, lr=LEARNING_RATE, model_output_path=OUT_DIR)"]},{"cell_type":"markdown","metadata":{},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test(OUT_DIR, tokenized_dataset['test'], task=TASK)"]},{"cell_type":"markdown","metadata":{},"source":["## Predict"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/plain":["\"When* the moon hits* your eye* , that ' s ' amore ' .\""]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["sentence = \"When the moon hits your eye, that's 'amore'.\"\n","sentence2 = \"The hallway smelt of boiled cabbage and old rag mats.\"\n","\n","predict_triggers(pretrained_model=OUT_DIR, sentence=sentence)\n","predict_frames(pretrained_model=OUT_DIR, sentence=sentence, visualize=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
